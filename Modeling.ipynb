{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>total_households</th>\n",
       "      <th>total_individuals</th>\n",
       "      <th>dw_00</th>\n",
       "      <th>dw_01</th>\n",
       "      <th>dw_02</th>\n",
       "      <th>dw_03</th>\n",
       "      <th>dw_04</th>\n",
       "      <th>dw_05</th>\n",
       "      <th>dw_06</th>\n",
       "      <th>...</th>\n",
       "      <th>pw_02</th>\n",
       "      <th>pw_03</th>\n",
       "      <th>pw_04</th>\n",
       "      <th>pw_05</th>\n",
       "      <th>pw_06</th>\n",
       "      <th>pw_07</th>\n",
       "      <th>pw_08</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>NL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.773757</td>\n",
       "      <td>1674.45058</td>\n",
       "      <td>5888.20750</td>\n",
       "      <td>0.933841</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.682270</td>\n",
       "      <td>24.734743</td>\n",
       "      <td>0.292039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.496661</td>\n",
       "      <td>1736.99230</td>\n",
       "      <td>6735.33812</td>\n",
       "      <td>0.696940</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018946</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.057127</td>\n",
       "      <td>0.019092</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.119311</td>\n",
       "      <td>24.757737</td>\n",
       "      <td>3.207775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.931425</td>\n",
       "      <td>2403.57591</td>\n",
       "      <td>7273.04995</td>\n",
       "      <td>0.810545</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083010</td>\n",
       "      <td>0.057560</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.040881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.142276</td>\n",
       "      <td>25.094093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  total_households  total_individuals     dw_00     dw_01  \\\n",
       "0  16.773757        1674.45058         5888.20750  0.933841  0.000846   \n",
       "1  21.496661        1736.99230         6735.33812  0.696940  0.001253   \n",
       "2  10.931425        2403.57591         7273.04995  0.810545  0.004517   \n",
       "\n",
       "      dw_02     dw_03     dw_04     dw_05     dw_06  ...     pw_02     pw_03  \\\n",
       "0  0.005490  0.000676  0.000000  0.001372  0.005750  ...  0.019968  0.002848   \n",
       "1  0.004402  0.000000  0.002301  0.001323  0.007575  ...  0.018946  0.014566   \n",
       "2  0.008891  0.003986  0.007735  0.000956  0.006686  ...  0.083010  0.057560   \n",
       "\n",
       "      pw_04     pw_05     pw_06  pw_07  pw_08        lat        lon        NL  \n",
       "0  0.007537  0.000000  0.012928      0      0 -29.682270  24.734743  0.292039  \n",
       "1  0.057127  0.019092  0.004131      0      0 -29.119311  24.757737  3.207775  \n",
       "2  0.010358  0.001421  0.040881      0      0 -29.142276  25.094093  0.000000  \n",
       "\n",
       "[3 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.drop(index = [1815], inplace=True) # removed weird row\n",
    "data.drop(['ADM4_PCODE','ward'], axis=1, inplace=True) # removed non-predictors\n",
    "# move target to first column\n",
    "target = data.pop('target')\n",
    "data.insert(0, 'target', target)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Description</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dw_00</td>\n",
       "      <td>Percentage of dwellings of type: House or brick/concrete block structure on a separate stand or yard or on a farm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dw_01</td>\n",
       "      <td>Percentage of dwellings of type: Traditional dwelling/hut/structure made of traditional materials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dw_02</td>\n",
       "      <td>Percentage of dwellings of type: Flat or apartment in a block of flats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Column  \\\n",
       "0  dw_00   \n",
       "1  dw_01   \n",
       "2  dw_02   \n",
       "\n",
       "                                                                                                         Description  \\\n",
       "0  Percentage of dwellings of type: House or brick/concrete block structure on a separate stand or yard or on a farm   \n",
       "1                  Percentage of dwellings of type: Traditional dwelling/hut/structure made of traditional materials   \n",
       "2                                             Percentage of dwellings of type: Flat or apartment in a block of flats   \n",
       "\n",
       "  Unnamed: 2 Unnamed: 3  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_desc = pd.read_csv('../variable_descriptions.csv')\n",
    "pd.set_option('display.max_colwidth', 200) # So that we can see the full descriptions\n",
    "var_desc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) General summary from EDA:\n",
    "#### 1) Relatively clean data with no missing values and many strong predictors\n",
    "#### 2) Makes sense to treat predictors based on the category of demographical information they belong to\n",
    "##### a) target = population + dwelling + school + tv + car + landline + language + race + water + gis\n",
    "#### 3) Predictors within each category are complementary percentages that add up to 1, and hence would likely to have high levels of intra-correlation and should be simplified whenever possible\n",
    "#### 4) Redundant predictors to drop in all cases: dw_12 , dw_13, stv_01, car_01, lln_00, lan_13, pw_07, pw_08\n",
    "#### 5) Engineered features to test: dw_00_02, dw_03_04, dw_07_08, lan_isafrican, race_dom5, pg_00_cat2, pw_02_06, pw_dom3\n",
    "#### 6) Many predictors require log-transform:\n",
    "##### ['dw_00','dw_01','dw_02','dw_03','dw_04','dw_05','dw_06','dw_07','dw_08','dw_09','dw_10','dw_11','dw_00_02','dw_03_04','dw_07_08','psa_03','psa_04','stv_00','car_00','lln_00','lan_00','lan_01','lan_02','lan_03','lan_05','lan_06','lan_07','lan_08','lan_09','lan_10','lan_11','lan_12','lan_14','lan_isafrican','pg_00','pg_01','pg_02','pg_03','pg_04','pw_00','pw_01','pw_02','pw_03','pw_04','pw_05','pw_06']\n",
    "#### 7) Normalize scaling of all predictors prior to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) For each category:\n",
    "#### Dwelling:\n",
    "##### 1) test a model where a) dwelling = dw_00_02 + dw_03_04 + dw_05 + dw_06 + dw_07_08 + dw_09 + dw_10 + dw_11 and b) dwelling = dw_00\n",
    "##### 2) dw_00-11, dw_00_02, dw_03_04, dw_07_08, if used, should be log-transformed\n",
    "##### 3) polynomial coefficients potentially better fit for dw_01, dw_03, dw_04, dw_07, dw_08, dw_03_04, dw_07_08\n",
    "#### Schooling: \n",
    "##### 1) test a model where school = psa_00\n",
    "##### 2) psa_03 and psa_04, if used, should be log-transformed\n",
    "#### TV/car/landline access:\n",
    "##### 1) all are binary categories\n",
    "##### 2) stv_00, car_00, lln_00, if used, should be log-transformed\n",
    "#### Language:\n",
    "##### 1) test a model where a) language = lan_08 and b) language = is_lan_african\n",
    "##### 2) lan_00-03, lan_05-12, lan_14, lan_isafrican if used, should be log-transformed\n",
    "##### 3) polynomial coefficients potentially better fit for lan_00, lan_01, lan_04, lan_isafrican\n",
    "#### Race:\n",
    "##### 1) test a model where a) race = race_dom5, and b) race = pg_00_cat2 + pg_01 + pg_02 + pg_03 + pg_04\n",
    "##### 2) pg_00-04, if used, should be log-transformed\n",
    "#### Water access:\n",
    "##### 1) test a model where a) water = pw_00 + pw_01 + pw_02_06, and b) water = pw_dom3\n",
    "##### 2) pw_02-06, if used, should be log-transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Modeling\n",
    "#### - Scoring = RMSE --> 'neg_root_mean_squared_error' (minimize)\n",
    "#### - Potential base models: linreg/polyreg + ridge/lasso/backward stepwise, regression forest, neural net\n",
    "#### - Potential optimization/tuning methods: K-fold, bagged ensembles, boosting (AdaBoost, XGBoost, LGBM), optimize tuning parameters like tree depth, neural net depth/architecture/optimizer/learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Building final dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing redundant predictors\n",
    "data.drop(['dw_12','dw_13','stv_01','car_01','lln_01','lan_13','pw_07','pw_08'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding engineered features\n",
    "data['dw_00_02'] = data[['dw_00','dw_01','dw_02']].sum(axis=1)\n",
    "data['dw_03_04'] = data[['dw_03','dw_04',]].sum(axis=1)\n",
    "data['dw_07_08'] = data[['dw_07','dw_08']].sum(axis=1)\n",
    "data['lan_isafrican'] = data[['lan_00','lan_02','lan_03','lan_04','lan_05','lan_06','lan_07','lan_09','lan_10','lan_11']].sum(axis=1)\n",
    "data['pg_00_cat2'] = (data.pg_00>0.9).astype(int)\n",
    "data['pw_02_06'] = data[['pw_02','pw_03','pw_04','pw_05','pw_06']].sum(axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data[['pg_00','pg_01','pg_02','pg_03','pg_04']].idxmax(axis=1).astype('category'), prefix='dom')], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data[['pw_00','pw_01','pw_02_06']].idxmax(axis=1).astype('category'), prefix='dom')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-transforming relevant predictors\n",
    "log_transform_needed = ['dw_00','dw_01','dw_02','dw_03','dw_04','dw_05','dw_06','dw_07','dw_08','dw_09','dw_10','dw_11','dw_00_02','dw_03_04','dw_07_08','psa_03','psa_04','stv_00','car_00','lln_00','lan_00','lan_01','lan_02','lan_03','lan_05','lan_06','lan_07','lan_08','lan_09','lan_10','lan_11','lan_12','lan_14','lan_isafrican','pg_00','pg_01','pg_02','pg_03','pg_04','pw_00','pw_01','pw_02','pw_03','pw_04','pw_05','pw_06']\n",
    "data[log_transform_needed] = data[log_transform_needed]+0.0001\n",
    "data[log_transform_needed] = np.log(data[log_transform_needed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>total_households</th>\n",
       "      <th>total_individuals</th>\n",
       "      <th>dw_00</th>\n",
       "      <th>dw_01</th>\n",
       "      <th>dw_02</th>\n",
       "      <th>dw_03</th>\n",
       "      <th>dw_04</th>\n",
       "      <th>dw_05</th>\n",
       "      <th>dw_06</th>\n",
       "      <th>...</th>\n",
       "      <th>lan_isafrican</th>\n",
       "      <th>pg_00_cat2</th>\n",
       "      <th>pw_02_06</th>\n",
       "      <th>dom_pg_00</th>\n",
       "      <th>dom_pg_01</th>\n",
       "      <th>dom_pg_02</th>\n",
       "      <th>dom_pg_03</th>\n",
       "      <th>dom_pw_00</th>\n",
       "      <th>dom_pw_01</th>\n",
       "      <th>dom_pw_02_06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.773757</td>\n",
       "      <td>1674.45058</td>\n",
       "      <td>5888.20750</td>\n",
       "      <td>-0.068342</td>\n",
       "      <td>-6.963562</td>\n",
       "      <td>-5.186750</td>\n",
       "      <td>-7.160772</td>\n",
       "      <td>-9.210340</td>\n",
       "      <td>-6.520896</td>\n",
       "      <td>-5.141335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043281</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.496661</td>\n",
       "      <td>1736.99230</td>\n",
       "      <td>6735.33812</td>\n",
       "      <td>-0.360912</td>\n",
       "      <td>-6.605512</td>\n",
       "      <td>-5.403209</td>\n",
       "      <td>-9.210340</td>\n",
       "      <td>-6.031712</td>\n",
       "      <td>-6.555033</td>\n",
       "      <td>-4.869827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113862</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.931425</td>\n",
       "      <td>2403.57591</td>\n",
       "      <td>7273.04995</td>\n",
       "      <td>-0.209925</td>\n",
       "      <td>-5.378009</td>\n",
       "      <td>-4.711545</td>\n",
       "      <td>-5.500117</td>\n",
       "      <td>-4.849205</td>\n",
       "      <td>-6.853223</td>\n",
       "      <td>-4.992851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193231</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  total_households  total_individuals     dw_00     dw_01  \\\n",
       "0  16.773757        1674.45058         5888.20750 -0.068342 -6.963562   \n",
       "1  21.496661        1736.99230         6735.33812 -0.360912 -6.605512   \n",
       "2  10.931425        2403.57591         7273.04995 -0.209925 -5.378009   \n",
       "\n",
       "      dw_02     dw_03     dw_04     dw_05     dw_06  ...  lan_isafrican  \\\n",
       "0 -5.186750 -7.160772 -9.210340 -6.520896 -5.141335  ...      -0.025741   \n",
       "1 -5.403209 -9.210340 -6.031712 -6.555033 -4.869827  ...      -0.041333   \n",
       "2 -4.711545 -5.500117 -4.849205 -6.853223 -4.992851  ...      -0.024053   \n",
       "\n",
       "   pg_00_cat2  pw_02_06  dom_pg_00  dom_pg_01  dom_pg_02  dom_pg_03  \\\n",
       "0           0  0.043281          0          1          0          0   \n",
       "1           0  0.113862          1          0          0          0   \n",
       "2           0  0.193231          1          0          0          0   \n",
       "\n",
       "   dom_pw_00  dom_pw_01  dom_pw_02_06  \n",
       "0          1          0             0  \n",
       "1          0          1             0  \n",
       "2          0          1             0  \n",
       "\n",
       "[3 rows x 66 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize model inputs here\n",
    "Y = data.target\n",
    "\n",
    "# Linear Model #1: all original predictors\n",
    "population_1 = ['total_households','total_individuals']\n",
    "dwelling_1 = ['dw_00','dw_01','dw_02','dw_03','dw_04','dw_05','dw_06','dw_07','dw_08','dw_09','dw_10','dw_11']\n",
    "school_1 = ['psa_00','psa_01','psa_02','psa_03','psa_04']\n",
    "tv_1 = ['stv_00']\n",
    "car_1 = ['car_00']\n",
    "landline_1 = ['lln_00']\n",
    "language_1 = ['lan_00','lan_01','lan_02','lan_03','lan_04','lan_05','lan_06','lan_07','lan_08','lan_09','lan_10','lan_11','lan_12','lan_14']\n",
    "race_1 = ['pg_00','pg_01','pg_02','pg_03','pg_04']\n",
    "water_1 = ['pw_00','pw_01','pw_02','pw_03','pw_04','pw_05','pw_06']\n",
    "gis_1 = ['lat','lon','NL']\n",
    "X_1 = data[population_1+dwelling_1+school_1+tv_1+car_1+landline_1+language_1+race_1+water_1+gis_1]\n",
    "\n",
    "# Linear Model #2: all original predictors + all engineered\n",
    "population_2 = ['total_households','total_individuals']\n",
    "dwelling_2 = ['dw_00','dw_01','dw_02','dw_03','dw_04','dw_05','dw_06','dw_07','dw_08','dw_09','dw_10','dw_11','dw_00_02','dw_03_04','dw_07_08']\n",
    "school_2 = ['psa_00','psa_01','psa_02','psa_03','psa_04']\n",
    "tv_2 = ['stv_00']\n",
    "car_2 = ['car_00']\n",
    "landline_2 = ['lln_00']\n",
    "language_2 = ['lan_00','lan_01','lan_02','lan_03','lan_04','lan_05','lan_06','lan_07','lan_08','lan_09','lan_10','lan_11','lan_12','lan_14','lan_isafrican']\n",
    "race_2 = ['pg_00','pg_01','pg_02','pg_03','pg_04','pg_00_cat2','dom_pg_00','dom_pg_01','dom_pg_02','dom_pg_03']\n",
    "water_2 = ['pw_00','pw_01','pw_02','pw_03','pw_04','pw_05','pw_06','pw_02_06','dom_pw_00','dom_pw_01','dom_pw_02_06']\n",
    "gis_2 = ['lat','lon','NL']\n",
    "X_2 = data[population_2+dwelling_2+school_2+tv_2+car_2+landline_2+language_2+race_2+water_2+gis_2]\n",
    "\n",
    "\n",
    "# Linear Model #3: reduced for dwelling, race, and water\n",
    "population_3 = ['total_households','total_individuals']\n",
    "dwelling_3 = ['dw_00_02','dw_03_04','dw_05','dw_06','dw_07_08','dw_09','dw_10','dw_11']\n",
    "school_3 = ['psa_00','psa_01','psa_02','psa_03','psa_04']\n",
    "tv_3 = ['stv_00']\n",
    "car_3 = ['car_00']\n",
    "landline_3 = ['lln_00']\n",
    "language_3 = ['lan_00','lan_01','lan_02','lan_03','lan_04','lan_05','lan_06','lan_07','lan_08','lan_09','lan_10','lan_11','lan_12','lan_14']\n",
    "race_3 = ['pg_00_cat2','pg_01','pg_02','pg_03','pg_04']\n",
    "water_3 = ['pw_00','pw_01','pw_02_06']\n",
    "gis_3 = ['lat','lon','NL']\n",
    "X_3 = data[population_3+dwelling_3+school_3+tv_3+car_3+landline_3+language_3+race_3+water_3+gis_3]\n",
    "\n",
    "# Linear Model #4: reduced for dwelling, race, and water + single predictor for the rest\n",
    "population_4 = ['total_households','total_individuals']\n",
    "dwelling_4 = ['dw_00_02','dw_03_04','dw_05','dw_06','dw_07_08','dw_09','dw_10','dw_11']\n",
    "school_4 = ['psa_00']\n",
    "tv_4 = ['stv_00']\n",
    "car_4 = ['car_00']\n",
    "landline_4 = ['lln_00']\n",
    "language_4 = ['lan_08']\n",
    "race_4 = ['dom_pg_00','dom_pg_01','dom_pg_02','dom_pg_03']\n",
    "water_4 = ['dom_pw_00','dom_pw_01','dom_pw_02_06']\n",
    "gis_4 = ['lat','lon','NL']\n",
    "X_4 = data[population_4+dwelling_4+school_4+tv_4+car_4+landline_4+language_4+race_4+water_4+gis_4]\n",
    "\n",
    "# Linear Model #5-6: single predictor for all\n",
    "population_5 = ['total_households','total_individuals']\n",
    "dwelling_5 = ['dw_00']\n",
    "school_5 = ['psa_00']\n",
    "tv_5 = ['stv_00']\n",
    "car_5 = ['car_00']\n",
    "landline_5 = ['lln_00']\n",
    "language_5_a = ['lan_08']\n",
    "language_5_b = ['lan_08']\n",
    "race_5 = ['dom_pg_00','dom_pg_01','dom_pg_02','dom_pg_03']\n",
    "water_5 = ['dom_pw_00','dom_pw_01','dom_pw_02_06']\n",
    "gis_5 = ['lat','lon','NL']\n",
    "X_5 = data[population_5+dwelling_5+school_5+tv_5+car_5+landline_5+language_5_a+race_5+water_5+gis_5]\n",
    "X_6 = data[population_5+dwelling_5+school_5+tv_5+car_5+landline_5+language_5_b+race_5+water_5+gis_5]\n",
    "\n",
    "X = [X_1, X_2, X_3, X_4, X_5, X_6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Index(['dw_00', 'dw_02', 'psa_00', 'psa_01', 'psa_02', 'psa_04', 'car_00',\n",
      "       'lln_00', 'lan_00', 'lan_03', 'lan_04', 'lan_07', 'lan_09', 'lan_10',\n",
      "       'pg_00', 'pg_01', 'pg_02', 'pw_00', 'lon'],\n",
      "      dtype='object')\n",
      "0.025\n",
      "0.0015143793832737451\n",
      "[2]\n",
      "Index(['dw_00', 'dw_02', 'dw_04', 'dw_09', 'dw_00_02', 'psa_00', 'psa_01',\n",
      "       'psa_02', 'psa_04', 'stv_00', 'car_00', 'lln_00', 'lan_00', 'lan_01',\n",
      "       'lan_03', 'lan_04', 'lan_07', 'lan_09', 'lan_10', 'lan_12',\n",
      "       'lan_isafrican', 'pg_00', 'pg_01', 'pg_02', 'pg_03', 'pg_00_cat2',\n",
      "       'dom_pg_00', 'dom_pg_02', 'dom_pg_03', 'pw_00', 'pw_01', 'pw_02_06',\n",
      "       'dom_pw_00', 'dom_pw_02_06', 'lon'],\n",
      "      dtype='object')\n",
      "0.05\n",
      "0.0018669976849473233\n",
      "[3]\n",
      "Index(['dw_00_02', 'dw_06', 'dw_09', 'psa_00', 'psa_01', 'psa_02', 'psa_04',\n",
      "       'stv_00', 'car_00', 'lln_00', 'lan_00', 'lan_01', 'lan_03', 'lan_04',\n",
      "       'lan_06', 'lan_07', 'lan_08', 'lan_09', 'lan_10', 'lan_12', 'lan_14',\n",
      "       'pg_00_cat2', 'pg_01', 'pg_02', 'pg_03', 'pw_00', 'pw_01', 'pw_02_06',\n",
      "       'lat', 'lon'],\n",
      "      dtype='object')\n",
      "0.025\n",
      "0.0014123152812920412\n",
      "[4]\n",
      "Index(['dw_00_02', 'dw_03_04', 'dw_06', 'dw_07_08', 'dw_09', 'dw_10', 'dw_11',\n",
      "       'psa_00', 'stv_00', 'car_00', 'lln_00', 'lan_08', 'dom_pg_00',\n",
      "       'dom_pg_01', 'dom_pg_02', 'dom_pg_03', 'dom_pw_00', 'dom_pw_01',\n",
      "       'dom_pw_02_06', 'lat', 'lon', 'NL'],\n",
      "      dtype='object')\n",
      "0.025\n",
      "0.0018669976849473233\n",
      "[5]\n",
      "Index(['dw_00', 'psa_00', 'car_00', 'dom_pg_02', 'dom_pw_02_06'], dtype='object')\n",
      "0.001\n",
      "0.0016238193743726452\n",
      "[6]\n",
      "Index(['dw_00', 'psa_00', 'car_00', 'dom_pg_02', 'dom_pw_02_06'], dtype='object')\n",
      "0.001\n",
      "0.0016238193743726452\n"
     ]
    }
   ],
   "source": [
    "# Linear regression\n",
    "\n",
    "linear_models = {}\n",
    "linear_rfes = {}\n",
    "linear_ridges = {}\n",
    "linear_lassos = {}\n",
    "\n",
    "for i, x in enumerate(X):\n",
    "    print([i+1])\n",
    "    # fit linear model\n",
    "    linear_models[i] = LinearRegression()\n",
    "    linear_models[i].fit(X=x, y=Y)\n",
    "    # backwards step-wise\n",
    "    linear_rfes[i] = RFECV(estimator=linear_models[i], cv=10, scoring=\"neg_root_mean_squared_error\")\n",
    "    linear_rfes[i].fit(X=x, y=Y)\n",
    "    print(x.columns[linear_rfes[i].support_])\n",
    "    # ridge\n",
    "    alphas = [0.001, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0]\n",
    "    linear_ridges[i] = RidgeCV(alphas=alphas, scoring=\"neg_root_mean_squared_error\", cv=10, normalize=True)\n",
    "    linear_ridges[i].fit(X=x, y=Y)\n",
    "    print(linear_ridges[i].alpha_)\n",
    "    # lasso\n",
    "    linear_lassos[i] = LassoCV(n_alphas=100, cv=10, normalize=True)\n",
    "    linear_lassos[i].fit(X=x, y=Y)\n",
    "    print(linear_lassos[i].alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2821.000000\n",
       "mean       24.516242\n",
       "std        10.285861\n",
       "min         1.671886\n",
       "25%        16.758903\n",
       "50%        24.157369\n",
       "75%        32.227600\n",
       "max        55.528423\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The quality of an RMSE score relates to the label's distribution. RMSE/std should at least be <1\n",
    "# Top 20 of Zindi is <3.5\n",
    "target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Linear: 16.785672688649964\n",
      "Linear RFE: 15.49575181429156\n",
      "Linear Ridge: 4.061346055473148\n",
      "Linear Lasso: 4.061456563887658\n",
      "Random Forest: 3.950808258307241\n",
      "[2]\n",
      "Linear: 16.92226459550187\n",
      "Linear RFE: 15.59475684272725\n",
      "Linear Ridge: 4.078761365080187\n",
      "Linear Lasso: 4.0667715679028795\n",
      "Random Forest: 4.009973008915052\n",
      "[3]\n",
      "Linear: 16.32937331629111\n",
      "Linear RFE: 15.468053062753205\n",
      "Linear Ridge: 4.002321292244011\n",
      "Linear Lasso: 4.003759789630182\n",
      "Random Forest: 3.9887136434650863\n",
      "[4]\n",
      "Linear: 20.536766901529234\n",
      "Linear RFE: 20.114680208548975\n",
      "Linear Ridge: 4.493270325361883\n",
      "Linear Lasso: 4.483317704041157\n",
      "Random Forest: 4.162012443084139\n",
      "[5]\n",
      "Linear: 21.351430105341556\n",
      "Linear RFE: 20.820670158402514\n",
      "Linear Ridge: 4.571865032758621\n",
      "Linear Lasso: 4.561846076555971\n",
      "Random Forest: 4.166834304570374\n",
      "[6]\n",
      "Linear: 21.351430105341556\n",
      "Linear RFE: 20.820670158402514\n",
      "Linear Ridge: 4.571865032758621\n",
      "Linear Lasso: 4.561846076555971\n",
      "Random Forest: 4.149152473731003\n"
     ]
    }
   ],
   "source": [
    "linear_results = {}\n",
    "rf_results = {}\n",
    "for i in range(len(X)):\n",
    "    pipeline_linear = Pipeline([('scaler', StandardScaler()),('model', LinearRegression())])\n",
    "    pipeline_rf = Pipeline([('scaler', StandardScaler()),('model', RandomForestRegressor())])\n",
    "    linear_results['cv_linear_{0}'.format(i+1)] = cross_val_score(estimator=pipeline_linear, X=X[i], y=Y, scoring='neg_mean_squared_error', cv=10)\n",
    "    linear_results['cv_linear_rfe_{0}'.format(i+1)] = cross_val_score(estimator=pipeline_linear, X=X[i][X[i].columns[linear_rfes[i].support_]], y=Y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    linear_results['cv_linear_ridge_{0}'.format(i+1)] = cross_val_score(estimator=Ridge(alpha=linear_ridges[i].alpha_), X=X[i], y=Y, scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "    linear_results['cv_linear_lasso_{0}'.format(i+1)] = cross_val_score(estimator=Lasso(alpha=linear_lassos[i].alpha_), X=X[i], y=Y, scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "    rf_results['cv_rf_{0}'.format(i+1)] = cross_val_score(pipeline_rf, X=X[i], y=Y, scoring='neg_root_mean_squared_error', cv=10)\n",
    "    print([i+1])\n",
    "    print('Linear:', -linear_results['cv_linear_{0}'.format(i+1)].mean())\n",
    "    print('Linear RFE:', -linear_results['cv_linear_rfe_{0}'.format(i+1)].mean())\n",
    "    print('Linear Ridge:', -linear_results['cv_linear_ridge_{0}'.format(i+1)].mean())\n",
    "    print('Linear Lasso:', -linear_results['cv_linear_lasso_{0}'.format(i+1)].mean())\n",
    "    print('Random Forest:', -rf_results['cv_rf_{0}'.format(i+1)].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
